{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7320b731-8734-4fa3-9a3d-f3c0b0ff3e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3e0ed9-ab75-4f0b-a56d-4fd13d206830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86013c39-32d3-4c44-8c01-b7ba75f41657",
   "metadata": {},
   "source": [
    "## load_documents:\n",
    "- Input:\n",
    "    - input_data: list of strings (documents) or list of file paths (strings)\n",
    "    - input_type: string ('documents' or 'file_paths')\n",
    "- Output: \n",
    "    - list of strings (documents)\n",
    "\n",
    "## build_sentence_graph:\n",
    "- Input: \n",
    "    - list of strings (documents)\n",
    "- Output: \n",
    "    - 2D list (adjacency list representing the sentence graph)\n",
    "\n",
    "## spectral_clustering:\n",
    "- Input: \n",
    "    - 2D list (adjacency list representing the sentence graph)\n",
    "- Output: \n",
    "    - list of lists, where each inner list contains spaCy sentence objects (each cluster)\n",
    "\n",
    "## fit:\n",
    "- Input: \n",
    "    - list of strings (documents)  \n",
    "    \n",
    "> No output (updates the self.clusters attribute)\n",
    "\n",
    "## compress_clusters:\n",
    "- Input: \n",
    "    - list of lists, where each inner list contains spaCy sentence objects (clusters)\n",
    "- Output: \n",
    "    - string (final summary)\n",
    "\n",
    "## transform:\n",
    "- Output: \n",
    "    - string (final summary)  \n",
    "    \n",
    "> No input (uses the self.clusters attribute)\n",
    "\n",
    "## fit_transform:\n",
    "- Input: \n",
    "    - list of strings (documents)\n",
    "    - Output: string (final summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eb24e55-d2c7-4710-967e-1bccaafe3b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "\n",
    "class SummPIPX:\n",
    "    def __init__(self, clustering_method='spectral_clustering', graph_method='build_sentence_graph', compression_method='compress_clusters'):\n",
    "        self.version = 'v1'\n",
    "        self.clustering_method = clustering_method\n",
    "        self.graph_method = graph_method\n",
    "        self.compression_method = compression_method\n",
    "\n",
    "    def __pdf_to_text__(self, path):\n",
    "        pdfreader = PyPDF2.PdfReader(path)\n",
    "        text=''\n",
    "        for page in pdfreader.pages:\n",
    "            text+=page.extract_text()\n",
    "        return text\n",
    "    \n",
    "    def load_documents(self, input_data, input_type='documents'):\n",
    "        # Check the input type\n",
    "        if input_type == 'documents':\n",
    "            # If input_type is 'documents', assume input_data represents the documents\n",
    "            documents = input_data\n",
    "        elif input_type == 'file_paths':\n",
    "            # If input_type is 'file_paths', assume input_data represents file paths\n",
    "            documents = [self.__pdf_to_text__(file) for file in files]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid input_type: {input_type}\")\n",
    "        return documents\n",
    "    \n",
    "    def build_sentence_graph(self, documents):\n",
    "        # Default graph building method\n",
    "        pass\n",
    "\n",
    "    def build_another_graph_method(self, documents):\n",
    "        # Another graph building method\n",
    "        pass\n",
    "\n",
    "    def spectral_clustering(self, sentence_graph):\n",
    "        # Default clustering method\n",
    "        return []\n",
    "\n",
    "    def another_clustering_method(self, sentence_graph):\n",
    "        # Another clustering method\n",
    "        return []\n",
    "\n",
    "    def compress_clusters(self, clusters):\n",
    "        nlp = spacy.load(\"en_core_web_md\")\n",
    "        summary_sentences = []\n",
    "\n",
    "        for cluster in clusters:\n",
    "            if len(cluster) == 1:\n",
    "                # If there's only one sentence in the cluster, add it to the summary\n",
    "                summary_sentences.append(cluster[0])\n",
    "            else:\n",
    "                # Calculate the similarity scores between all sentences in the cluster\n",
    "                similarity_matrix = [[sent1.similarity(sent2) for sent2 in cluster] for sent1 in cluster]\n",
    "\n",
    "                # Calculate the sum of similarity scores for each sentence\n",
    "                similarity_sums = [sum(row) for row in similarity_matrix]\n",
    "\n",
    "                # Find the index of the sentence with the highest similarity score sum\n",
    "                most_relevant_index = similarity_sums.index(max(similarity_sums))\n",
    "\n",
    "                # Add the most relevant sentence to the summary\n",
    "                summary_sentences.append(cluster[most_relevant_index])\n",
    "\n",
    "        # Concatenate the summary sentences\n",
    "        summary = \" \".join(summary_sentences)\n",
    "        return summary\n",
    "\n",
    "    def another_compression_method(self, clusters):\n",
    "        # Another compression method\n",
    "        # ...\n",
    "        return ''\n",
    "\n",
    "    def fit(self, documents):\n",
    "        # Call the appropriate graph building method\n",
    "        graph_method = getattr(self, self.graph_method)\n",
    "        sentence_graph = graph_method(documents)\n",
    "        \n",
    "        # Call the appropriate clustering method\n",
    "        clustering_method = getattr(self, self.clustering_method)\n",
    "        self.clusters = clustering_method(sentence_graph)\n",
    "\n",
    "    def transform(self):\n",
    "        # Call the appropriate compression method\n",
    "        compression_method = getattr(self, self.compression_method)\n",
    "        summary = compression_method(self.clusters)\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cc3ee-facd-4b66-b1e9-e8b606c17177",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ce2f78-87a1-448a-a46b-4a74a349336c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [\n",
    "    'dataset/NeuralNetworks/1460210.pdf', \n",
    "    'dataset/NeuralNetworks/Oken.pdf',\n",
    "    'dataset/NeuralNetworks/week7b-neuralnetwork.pdf'\n",
    "]\n",
    "\n",
    "summpip = SummPIPX()\n",
    "documents = summpip.load_documents(files, input_type='file_paths')\n",
    "summpip.fit(documents)\n",
    "summpip.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be04211-5084-4800-ab25-eb74d778fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SummPIP-Kernel",
   "language": "python",
   "name": "summpip-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
